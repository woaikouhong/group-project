Group Project
A new line
Another line in 'cat branch'

Our Group is going to do CASE 1,CASE 2.CASE 3.

Case 1

What facilities and equipment will be required (hard disk space, backup server, central repository, off-site repository, etc.) 
What data management practices (backups, storage, access control,
archiving etc.) will be used


In this case, the data size is big and is keep renewing every day. According to the case, the first part of data is the ROMV data, which is collected monthly and converted to NetCDF formatted data for storage. Every day, there will be in total 800MB NetCDF data being produced, and the NetCDF data size so far has reached 500GB.  The Second part of the data is the field notes, the size of the data collect form filed notes is around 2GB so far. Third part is the csv files of complex stimulation models, which accumulated to 200GB now. 
Our group conducted an estimation of a three-year data storage.  First for the NetCDF data, yearly storage that required is 800MB per day * 365 days equal to 285GB. In 3 years, NetCDF data would at least reach 285GB* 3 years which is 855GB. Second for the File notes the estimation is going to be doubled which is at lease 4GB in 3 years, due to the increase in funding. Third, suppose the stimulation models is going to increase at the same speed as the NetCDF data, therefore in 1 year it will reach (200GB/500GB) * 285GB=114GB. In three years would reach 114GB *3= 342GB. Therefore, in total the storage that Dr Periwinkle need will be at least 1201GB.

Also due to the increase funding, Dr. Periwinkles lab is now collecting substantially more data than ever before. The size of the data files is going to keep expanding, therefore the estimate storage is going to be larger than what our team predicted above. The storage requirement is high, approximately over 2 TB. The current and historical data are stored in hard drives but as the data size keep increasing the hard drive is not a very good choose. Hard drives are expensive and have the risk to be lost to disaster and will create unnecessary difficulty to organize the data in practical  sequence. The data is going to be renewed and accessed very frequently, making the hard drive a very inconvenient option for quick data access and sharing. Therefore, our team suggest Dr. Periwinkle to move all the data to the cloud drive. Cloud allows the  data owners to set up access control and also can set up  access limit by IP address and other types of user authorizations. Dr. Periwinkle can set up constraints on who can edit the internal data and can provide view only version for student’s general use. For the CSV files which contains the situation of model, the Version control is necessary, cloud drive would allow Dr. Periwinkle’s research team member to track the changes and keep different versions of the model. Backups are also important; the hard drive is useful, and it should save the all the raw data periodically on a hard drive and an another backup cloud drive, to prevent the loss of data, unauthorized access and incorrect modify.




